{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_creation_VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCMbNrqYJuQC",
        "colab_type": "code",
        "outputId": "6ae7ffd7-4722-46ff-dfb6-4803b56a9c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwyOvYFpJ3_k",
        "colab_type": "code",
        "outputId": "33e220a5-63f0-4c0a-abce-9ab80f0d4fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "from keras.layers import Dense # , Flatten\n",
        "from keras.applications import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#creating the classifier\n",
        "image_resize = 224\n",
        "batch_size_training = 32\n",
        "batch_size_validation = 32\n",
        "\n",
        "# get number of classes\n",
        "folders = glob('/content/drive/My Drive/TransferLearning_OpenCV/dataset/train/*')\n",
        "num_classes = len(folders)\n",
        "print(num_classes)\n",
        "\n",
        "#building the model\n",
        "model = Sequential()\n",
        "model.add(VGG16(\n",
        "    input_shape=[image_resize,image_resize]+[3],\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    weights='imagenet',\n",
        "    ))\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(1000, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# don't train existing weights\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "print(\"layers of the model = \\n\",model.layers,\"\\n\")\n",
        "# print(\"vgg16 layers = \\n\",model.layers[0].layers)\n",
        "# print(\"output layer = \\n\",model.layers[1])\n",
        "print(model.summary())\n",
        "\n",
        "# compile model\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "#constructing DataGenerator for training and validation set\n",
        "data_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    #rescale = 1./255,\n",
        "    #shear_range = 0.2,\n",
        "    #zoom_range = 0.2,\n",
        "    #horizontal_flip = True\n",
        ")\n",
        "\n",
        "# reading the images\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "    '/content/drive/My Drive/TransferLearning_OpenCV/dataset/train',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_training,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    '/content/drive/My Drive/TransferLearning_OpenCV/dataset/valid',\n",
        "    target_size = (image_resize, image_resize),\n",
        "    batch_size = batch_size_validation,\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "steps_per_epoch_training = len(train_generator)\n",
        "steps_per_epoch_validation = len(validation_generator)\n",
        "num_epochs = 3\n",
        "\n",
        "# fitting the model\n",
        "fit_history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch_training,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=steps_per_epoch_validation,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# loss\n",
        "plt.plot(fit_history.history['loss'], label='train loss')\n",
        "plt.plot(fit_history.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# accuracies\n",
        "plt.plot(fit_history.history['accuracy'], label='train acc')\n",
        "plt.plot(fit_history.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "model.save('facefeatures_vgg16.h5')\n",
        "model.save(\"/content/drive/My Drive/TransferLearning_OpenCV/facefeatures_vgg16.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "layers of the model = \n",
            " [<keras.engine.training.Model object at 0x7fb86eb88630>, <keras.layers.core.Dense object at 0x7fb80c131a58>] \n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 1539      \n",
            "=================================================================\n",
            "Total params: 14,716,227\n",
            "Trainable params: 1,539\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "None\n",
            "Found 596 images belonging to 3 classes.\n",
            "Found 599 images belonging to 3 classes.\n",
            "Epoch 1/3\n",
            "19/19 [==============================] - 551s 29s/step - loss: 3.1643 - accuracy: 0.2852 - val_loss: 0.8100 - val_accuracy: 0.6628\n",
            "Epoch 2/3\n",
            "19/19 [==============================] - 8s 432ms/step - loss: 0.2124 - accuracy: 0.9211 - val_loss: 0.0756 - val_accuracy: 0.9766\n",
            "Epoch 3/3\n",
            "18/19 [===========================>..] - ETA: 0s - loss: 0.0392 - accuracy: 0.9965"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc_XpSiIH_X7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}